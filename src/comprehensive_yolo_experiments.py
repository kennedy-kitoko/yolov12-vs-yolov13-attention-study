#!/usr/bin/env python3
"""
üöÄ LANCEUR EXP√âRIENCES COMPARATIVES YOLO COMPLET
YOLOv12 vs YOLOv13 avec SDPA vs Flash Attention
D√©velopp√© par Kennedy Kitoko üá®üá©
"""

import os
import sys
import json
import time
import subprocess
import traceback
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple

class ComprehensiveYOLOExperimentLauncher:
    """
    Lanceur d'exp√©riences comparatives pour YOLOv12 vs YOLOv13
    avec m√©canismes d'attention SDPA vs Flash Attention
    """
    
    def __init__(self, dataset_path: str = None):
        self.session_id = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.base_dir = f"yolo_comparative_experiments_{self.session_id}"
        
        # Configuration dataset optimis√©e pour Kennedy
        self.dataset_paths = self._find_dataset_paths(dataset_path)
        
        # Configuration exp√©riences optimis√©e pour le setup
        self.optimized_config = {
            'cpu_cores': 12,
            'ram_gb': 39,
            'recommended_epochs': 100,
            'recommended_batch': 16,
            'workers': 8,  # 2/3 des cores pour DataLoader
            'mixed_precision': True,  # AMP avec beaucoup de RAM
            'cache_images': True,  # Cache avec 39GB RAM
            'multi_scale_training': True
        }
        
        self.results = {
            'session_info': {
                'session_id': self.session_id,
                'start_time': datetime.now().isoformat(),
                'researcher': 'Kennedy Kitoko üá®üá©',
                'experiment_type': 'YOLOv12 vs YOLOv13 - SDPA vs Flash Attention Comprehensive Comparison',
                'dataset_used': None
            },
            'validation_results': {},
            'experiments': {
                'yolov12_sdpa': {},
                'yolov12_flash': {},
                'yolov13_sdpa': {},
                'yolov13_flash': {}
            },
            'comparative_analysis': {},
            'session_summary': {}
        }
        
        # Cr√©ation structure session
        os.makedirs(self.base_dir, exist_ok=True)
        
        print(f"üöÄ Lanceur d'exp√©riences YOLO comparatives initialis√©")
        print(f"üìÅ Session: {self.session_id}")
        print(f"üìÇ Dossier: {self.base_dir}")
    
    def _find_dataset_paths(self, custom_path: str = None) -> List[str]:
        """Recherche intelligente du dataset"""
        paths_to_check = []
        
        if custom_path:
            paths_to_check.append(custom_path)
        
        # Ajout path Kennedy dans la recherche
        common_paths = [
            '/mnt/c/Users/kitok/Desktop/SmartFarm_OS/IA/YOLO12_FLASH_attn/Weeds-3',  # Path Kennedy
            'Weeds-3',
            './Weeds-3',
            '../Weeds-3',
            '../../Weeds-3',
            '/content/Weeds-3',  # Google Colab
            '/kaggle/input/weeds-3',  # Kaggle
            '/mnt/c/Users/kitok/Desktop/SmartFarm_OS/IA/datasets/Weeds-3',  # Path alternatif Kennedy
        ]
        
        paths_to_check.extend(common_paths)
        
        valid_paths = []
        for path in paths_to_check:
            if os.path.exists(os.path.join(path, 'train', 'images')):
                valid_paths.append(os.path.abspath(path))
        
        return valid_paths
    
    def comprehensive_validation(self) -> bool:
        """Validation compl√®te de l'environnement"""
        print("\nüîç VALIDATION COMPL√àTE DE L'ENVIRONNEMENT...")
        
        validation = {
            'python_ok': False,
            'torch_ok': False,
            'cuda_ok': False,
            'ultralytics_ok': False,
            'flash_attn_ok': False,
            'pillow_ok': False,
            'dataset_ok': False,
            'yolov12_weights_ok': False,
            'yolov13_weights_ok': False,
            'sdpa_backends_ok': False
        }
        
        # Python
        if sys.version_info >= (3, 8):
            validation['python_ok'] = True
            print(f"‚úÖ Python {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}")
        else:
            print(f"‚ùå Python {sys.version_info.major}.{sys.version_info.minor} (requis: ‚â•3.8)")
        
        # PyTorch + CUDA
        try:
            import torch
            validation['torch_ok'] = True
            print(f"‚úÖ PyTorch {torch.__version__}")

            if torch.cuda.is_available():
                validation['cuda_ok'] = True
                device_name = torch.cuda.get_device_name(0)
                memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9
                print(f"‚úÖ CUDA - {device_name} ({memory_gb:.1f} GB)")
            else:
                print("‚ùå CUDA non disponible")
        except ImportError:
            print("‚ùå PyTorch non disponible")
        except Exception as e:
            print(f"‚ùå Erreur lors de la v√©rification PyTorch/CUDA : {e}")
        
        # Test SDPA backends avec gestion d'erreurs
        try:
            # Tentative import avec gestion d'erreurs pour PyTorch 2.2.2
            try:
                from torch.nn.attention import SDPBackend
                backends = []
                if hasattr(torch.backends.cuda, 'flash_sdp_enabled') and torch.backends.cuda.flash_sdp_enabled():
                    backends.append("Flash")
                if hasattr(torch.backends.cuda, 'mem_efficient_sdp_enabled') and torch.backends.cuda.mem_efficient_sdp_enabled():
                    backends.append("Efficient")
                if hasattr(torch.backends.cuda, 'math_sdp_enabled') and torch.backends.cuda.math_sdp_enabled():
                    backends.append("Math")

                if backends:
                    validation['sdpa_backends_ok'] = True
                    print(f"‚úÖ SDPA Backends: {', '.join(backends)}")
                else:
                    print("‚ö†Ô∏è SDPA Backends: Aucun backend d√©tect√©")

            except ImportError:
                # Fallback pour PyTorch 2.2.2
                print("‚ö†Ô∏è torch.nn.attention non disponible - PyTorch 2.2.2 compatibility")
                validation['sdpa_backends_ok'] = True  # Assume SDPA is available

        except Exception as e:
            print(f"‚ö†Ô∏è SDPA Backends: Erreur {e}")
        
        # Ultralytics
        try:
            from ultralytics import YOLO
            validation['ultralytics_ok'] = True
            print("‚úÖ Ultralytics YOLO")
            
            # Test t√©l√©chargement mod√®les
            try:
                # YOLOv12
                yolo12_model = YOLO('yolo12n.pt')
                validation['yolov12_weights_ok'] = True
                print("‚úÖ YOLOv12-N weights disponibles")
            except Exception as e:
                print(f"‚ö†Ô∏è YOLOv12-N weights: {e}")
            
            try:
                # YOLOv13 (hypoth√©tique - adapter selon disponibilit√©)
                yolo13_model = YOLO('yolov13n.pt')
                validation['yolov13_weights_ok'] = True
                print("‚úÖ YOLOv13-N weights disponibles")
            except Exception as e:
                print(f"‚ö†Ô∏è YOLOv13-N weights: {e}")
                
        except ImportError:
            print("‚ùå Ultralytics non disponible")
        
        # Flash Attention
        try:
            import flash_attn
            validation['flash_attn_ok'] = True
            version = getattr(flash_attn, '__version__', 'unknown')
            print(f"‚úÖ Flash Attention {version}")
        except ImportError:
            print("‚ö†Ô∏è Flash Attention non disponible (non bloquant)")
        
        # Pillow
        try:
            from PIL import Image
            validation['pillow_ok'] = True
            print("‚úÖ Pillow (PIL)")
        except ImportError:
            print("‚ö†Ô∏è Pillow non accessible")
        
        # Dataset
        if self.dataset_paths:
            validation['dataset_ok'] = True
            dataset_path = self.dataset_paths[0]
            self.results['session_info']['dataset_used'] = dataset_path
            print(f"‚úÖ Dataset: {dataset_path}")
            
            # V√©rification structure
            train_images = len(list(Path(dataset_path, 'train', 'images').glob('*')))
            val_images = len(list(Path(dataset_path, 'val', 'images').glob('*')))
            print(f"   üìä Images: {train_images} train, {val_images} val")
        else:
            print("‚ùå Dataset non trouv√©")
        
        # R√©sum√© validation
        critical_checks = ['python_ok', 'torch_ok', 'cuda_ok', 'ultralytics_ok', 'dataset_ok']
        critical_passed = sum(validation[check] for check in critical_checks)
        total_passed = sum(validation.values())
        
        ready = critical_passed >= 5 and validation['yolov12_weights_ok']
        
        print(f"\nüìä Validation: {total_passed}/{len(validation)} checks")
        print(f"üéØ Critique: {critical_passed}/{len(critical_checks)} essentiels")
        print(f"üèÅ Pr√™t pour exp√©riences: {'Oui' if ready else 'Non'}")
        
        self.results['validation_results'] = {
            'checks': validation,
            'ready_for_experiments': ready,
            'critical_passed': critical_passed,
            'total_passed': total_passed
        }
        
        return ready
    
    def get_memory_usage(self) -> float:
        """Utilisation m√©moire actuelle en MB"""
        try:
            import psutil
            process = psutil.Process()
            return process.memory_info().rss / 1024 / 1024
        except:
            return 0.0
    
    def get_gpu_memory_usage(self) -> Tuple[float, float]:
        """Utilisation m√©moire GPU (used, total) en GB"""
        try:
            import torch
            if torch.cuda.is_available():
                used = torch.cuda.memory_allocated(0) / 1e9
                total = torch.cuda.get_device_properties(0).total_memory / 1e9
                return used, total
        except:
            pass
        return 0.0, 0.0
    
    def run_yolo_experiment(self, 
                          model_version: str, 
                          attention_type: str,
                          epochs: int = 100,  # Optimis√© pour setup Kennedy
                          batch_size: int = 16) -> Dict[str, Any]:  # Batch plus grand
        """
        Exp√©rience YOLO g√©n√©rique
        
        Args:
            model_version: 'yolov12' ou 'yolov13'
            attention_type: 'sdpa' ou 'flash'
            epochs: Nombre d'√©poques
            batch_size: Taille du batch
        """
        experiment_name = f"{model_version}_{attention_type}"
        print(f"\nüî¨ EXP√âRIENCE {experiment_name.upper()}...")
        
        try:
            # Import PyTorch en premier
            import torch
            from ultralytics import YOLO
            
            # Configuration optimis√©e pour setup Kennedy
            if model_version == "yolov12":
                model_file = "yolo12n.pt"
            elif model_version == "yolov13":
                model_file = "yolov13n.pt"
            else:
                model_file = f"{model_version}n.pt"
            data_file = os.path.join(self.dataset_paths[0], 'data.yaml')
            
            config = {
                'model': model_file,
                'data': data_file,
                'epochs': epochs,
                'batch': batch_size,
                'imgsz': 640,
                'device': 'cuda:0' if torch.cuda.is_available() else 'cpu',
                'amp': True,  # Mixed precision activ√© avec beaucoup de RAM
                'optimizer': 'AdamW',
                'lr0': 0.001,
                'lrf': 0.01,  # Learning rate final
                'momentum': 0.937,
                'weight_decay': 0.0005,
                'warmup_epochs': 3,
                'warmup_momentum': 0.8,
                'warmup_bias_lr': 0.1,
                'patience': 50,  # Plus de patience avec plus d'√©poques
                'project': self.base_dir,
                'name': experiment_name,
                'save_period': 25,  # Sauvegarde tous les 25 √©poques
                'workers': self.optimized_config['workers'],  # 8 workers
                'cache': 'ram',  # Cache en RAM avec 39GB
                'rect': True,  # Rectangular training
                'cos_lr': True,  # Cosine LR scheduler
                'close_mosaic': 10,  # Disable mosaic last 10 epochs
                'resume': False,
                'overlap_mask': True,
                'mask_ratio': 4,
                'dropout': 0.0,
                'verbose': True,
                # Optimisations sp√©cifiques setup Kennedy
                'multi_scale': True,  # Multi-scale training
                'copy_paste': 0.1,  # Copy-paste augmentation
                'mixup': 0.1,  # Mixup augmentation
                'hsv_h': 0.015,  # HSV-Hue augmentation
                'hsv_s': 0.7,   # HSV-Saturation
                'hsv_v': 0.4,   # HSV-Value
                'degrees': 0.0,  # Rotation degrees
                'translate': 0.1,  # Translation
                'scale': 0.5,   # Scale
                'shear': 0.0,   # Shear
                'perspective': 0.0,  # Perspective
                'flipud': 0.0,  # Flip up-down
                'fliplr': 0.5,  # Flip left-right
                'mosaic': 1.0,  # Mosaic augmentation
            }
            
            # Import et monitoring
            start_time = time.time()
            start_memory = self.get_memory_usage()
            start_gpu_memory, total_gpu_memory = self.get_gpu_memory_usage()
            
            # Configuration attention selon PyTorch 2.2.2
            if attention_type == 'sdpa':
                print("üéØ Configuration SDPA...")
                os.environ['TORCH_CUDNN_BENCHMARK'] = '1'
                os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
                
                # Configuration SDPA pour PyTorch 2.2.2
                try:
                    # Essai avec la nouvelle API
                    torch.backends.cuda.enable_flash_sdp(False)
                    torch.backends.cuda.enable_mem_efficient_sdp(True)
                    torch.backends.cuda.enable_math_sdp(True)
                    print("‚úÖ SDPA configur√© via torch.backends")
                except AttributeError:
                    # Fallback pour versions ant√©rieures
                    print("‚ö†Ô∏è Using fallback SDPA configuration")
                
            elif attention_type == 'flash':
                print("üî• Configuration Flash Attention...")
                try:
                    import flash_attn
                    print(f"‚úÖ Flash Attention {getattr(flash_attn, '__version__', 'unknown')} d√©tect√©")
                    
                    os.environ['FLASH_ATTENTION_FORCE_USE'] = '1'
                    os.environ['FLASH_ATTENTION_SKIP_CUDA_BUILD'] = '0'
                    
                    # Configuration Flash Attention
                    try:
                        torch.backends.cuda.enable_flash_sdp(True)
                        torch.backends.cuda.enable_mem_efficient_sdp(False)
                        torch.backends.cuda.enable_math_sdp(False)
                        print("‚úÖ Flash Attention configur√© via torch.backends")
                    except AttributeError:
                        print("‚ö†Ô∏è Using fallback Flash Attention configuration")
                        
                except ImportError:
                    print("‚ùå Flash Attention non disponible, basculement vers SDPA")
                    return self.run_yolo_experiment(model_version, 'sdpa', epochs, batch_size)
            
            print("üìã Configuration:")
            for k, v in config.items():
                print(f"   {k}: {v}")
            
            # Chargement mod√®le
            print(f"üì¶ Chargement {model_file}...")
            model = YOLO(config['model'])
            
            # YOLOv13 sp√©cifique - Configuration HyperACE si disponible
            if model_version == 'yolov13' and attention_type == 'flash':
                try:
                    # Hypoth√©tique: activation HyperACE avec Flash Attention
                    print("üß† Tentative activation HyperACE avec Flash Attention...")
                    # model.model.enable_hyperace(attention='flash')  # API hypoth√©tique
                except Exception as e:
                    print(f"‚ö†Ô∏è HyperACE non configur√©: {e}")
            
            # Entra√Ænement
            print("üöÄ D√©marrage entra√Ænement...")
            results = model.train(**{k: v for k, v in config.items() if k not in ['model']})
            
            # M√©triques finales
            end_time = time.time()
            end_memory = self.get_memory_usage()
            end_gpu_memory, _ = self.get_gpu_memory_usage()
            duration = end_time - start_time
            
            # Extraction m√©triques d√©taill√©es
            metrics = {}
            if hasattr(results, 'results_dict'):
                metrics = {
                    'mAP50': results.results_dict.get('metrics/mAP50(B)', 0),
                    'mAP50_95': results.results_dict.get('metrics/mAP50-95(B)', 0),
                    'precision': results.results_dict.get('metrics/precision(B)', 0),
                    'recall': results.results_dict.get('metrics/recall(B)', 0),
                    'fitness': results.results_dict.get('fitness', 0)
                }
            
            # R√©sultats exp√©rience
            experiment_result = {
                'success': True,
                'model_version': model_version,
                'attention_type': attention_type,
                'duration_seconds': duration,
                'duration_minutes': duration / 60,
                'config': config,
                'metrics': metrics,
                'performance': {
                    'memory_start_mb': start_memory,
                    'memory_end_mb': end_memory,
                    'memory_used_mb': end_memory - start_memory,
                    'gpu_memory_start_gb': start_gpu_memory,
                    'gpu_memory_end_gb': end_gpu_memory,
                    'gpu_memory_used_gb': end_gpu_memory - start_gpu_memory,
                    'total_gpu_memory_gb': total_gpu_memory
                },
                'results_path': str(results.save_dir) if hasattr(results, 'save_dir') else None,
                'best_weights': None,
                'timestamp': datetime.now().isoformat()
            }
            
            # Recherche meilleurs poids
            if experiment_result['results_path']:
                weights_dir = Path(experiment_result['results_path']) / 'weights'
                if weights_dir.exists():
                    best_pt = weights_dir / 'best.pt'
                    if best_pt.exists():
                        experiment_result['best_weights'] = str(best_pt)
            
            print(f"‚úÖ {experiment_name.upper()} termin√© en {duration/60:.1f} minutes")
            print(f"üìä M√©moire utilis√©e: {end_memory - start_memory:.1f} MB")
            print(f"üéÆ GPU m√©moire utilis√©e: {end_gpu_memory - start_gpu_memory:.2f} GB")
            if metrics:
                print(f"üìà mAP50: {metrics.get('mAP50', 0):.3f}")
                print(f"üìà mAP50-95: {metrics.get('mAP50_95', 0):.3f}")
            
            return experiment_result
            
        except Exception as e:
            print(f"‚ùå Erreur {experiment_name}: {e}")
            print(f"üîç Traceback: {traceback.format_exc()}")
            
            return {
                'success': False,
                'model_version': model_version,
                'attention_type': attention_type,
                'error': str(e),
                'traceback': traceback.format_exc(),
                'duration_seconds': time.time() - start_time if 'start_time' in locals() else 0,
                'timestamp': datetime.now().isoformat()
            }
    
    def run_all_experiments(self, epochs: int = 100, batch_size: int = 16) -> bool:
        """Lance toutes les exp√©riences comparatives"""
        print(f"\n{'='*60}")
        print("üöÄ LANCEMENT EXP√âRIENCES COMPARATIVES COMPL√àTES")
        print(f"{'='*60}")
        
        experiments_config = [
        #    ('yolov12', 'sdpa'),
        #    ('yolov12', 'flash'),
        #    ('yolov13', 'sdpa'),
            ('yolov13', 'flash')
        ]
        
        successful_experiments = 0
        
        for i, (model_version, attention_type) in enumerate(experiments_config, 1):
            print(f"\n{'='*20}")
            print(f"EXP√âRIENCE {i}/4: {model_version.upper()} + {attention_type.upper()}")
            print(f"{'='*20}")
            
            result = self.run_yolo_experiment(model_version, attention_type, epochs, batch_size)
            experiment_key = f"{model_version}_{attention_type}"
            self.results['experiments'][experiment_key] = result
            
            if result['success']:
                successful_experiments += 1
                print(f"‚úÖ Exp√©rience {experiment_key} r√©ussie")
            else:
                print(f"‚ùå Exp√©rience {experiment_key} √©chou√©e")
            
            # Pause entre exp√©riences pour lib√©rer m√©moire
            if i < len(experiments_config):
                print("‚è∏Ô∏è Pause nettoyage m√©moire...")
                try:
                    import torch
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    import gc
                    gc.collect()
                    time.sleep(5)
                except:
                    pass
        
        print(f"\nüìä Exp√©riences termin√©es: {successful_experiments}/{len(experiments_config)}")
        return successful_experiments > 0
    
    def comprehensive_analysis(self) -> Dict[str, Any]:
        """Analyse comparative compl√®te des r√©sultats"""
        print(f"\n{'='*60}")
        print("üìä ANALYSE COMPARATIVE COMPL√àTE")
        print(f"{'='*60}")
        
        try:
            experiments = self.results['experiments']
            successful_experiments = {k: v for k, v in experiments.items() if v.get('success', False)}
            
            if not successful_experiments:
                print("‚ùå Aucune exp√©rience r√©ussie pour analyse")
                return {}
            
            analysis = {
                'timestamp': datetime.now().isoformat(),
                'successful_experiments': list(successful_experiments.keys()),
                'failed_experiments': [k for k, v in experiments.items() if not v.get('success', False)],
                'model_comparison': {},
                'attention_comparison': {},
                'performance_ranking': {},
                'recommendations': []
            }
            
            # Comparaison par mod√®le
            yolov12_results = {k: v for k, v in successful_experiments.items() if 'yolov12' in k}
            yolov13_results = {k: v for k, v in successful_experiments.items() if 'yolov13' in k}
            
            if yolov12_results and yolov13_results:
                print("\nüîç COMPARAISON MOD√àLES YOLOv12 vs YOLOv13")
                
                # Moyennes YOLOv12
                yolov12_metrics = self._calculate_average_metrics(yolov12_results)
                # Moyennes YOLOv13
                yolov13_metrics = self._calculate_average_metrics(yolov13_results)
                
                analysis['model_comparison'] = {
                    'yolov12_average': yolov12_metrics,
                    'yolov13_average': yolov13_metrics,
                    'winner': 'yolov13' if yolov13_metrics['mAP50'] > yolov12_metrics['mAP50'] else 'yolov12',
                    'mAP_difference': abs(yolov13_metrics['mAP50'] - yolov12_metrics['mAP50']),
                    'speed_difference_minutes': abs(yolov13_metrics['duration_minutes'] - yolov12_metrics['duration_minutes'])
                }
                
                print(f"YOLOv12 mAP50 moyen: {yolov12_metrics['mAP50']:.3f}")
                print(f"YOLOv13 mAP50 moyen: {yolov13_metrics['mAP50']:.3f}")
                print(f"Gagnant mod√®le: {analysis['model_comparison']['winner'].upper()}")
            
            # Comparaison par attention
            sdpa_results = {k: v for k, v in successful_experiments.items() if 'sdpa' in k}
            flash_results = {k: v for k, v in successful_experiments.items() if 'flash' in k}
            
            if sdpa_results and flash_results:
                print("\nüîç COMPARAISON ATTENTION SDPA vs Flash")
                
                sdpa_metrics = self._calculate_average_metrics(sdpa_results)
                flash_metrics = self._calculate_average_metrics(flash_results)
                
                analysis['attention_comparison'] = {
                    'sdpa_average': sdpa_metrics,
                    'flash_average': flash_metrics,
                    'winner': 'flash' if flash_metrics['mAP50'] > sdpa_metrics['mAP50'] else 'sdpa',
                    'mAP_difference': abs(flash_metrics['mAP50'] - sdpa_metrics['mAP50']),
                    'speed_difference_minutes': abs(flash_metrics['duration_minutes'] - sdpa_metrics['duration_minutes'])
                }
                
                print(f"SDPA mAP50 moyen: {sdpa_metrics['mAP50']:.3f}")
                print(f"Flash mAP50 moyen: {flash_metrics['mAP50']:.3f}")
                print(f"Gagnant attention: {analysis['attention_comparison']['winner'].upper()}")
            
            # Ranking performance
            ranking = []
            for exp_name, exp_data in successful_experiments.items():
                metrics = exp_data.get('metrics', {})
                performance = exp_data.get('performance', {})
                
                ranking.append({
                    'experiment': exp_name,
                    'mAP50': metrics.get('mAP50', 0),
                    'mAP50_95': metrics.get('mAP50_95', 0),
                    'duration_minutes': exp_data.get('duration_minutes', 0),
                    'memory_used_mb': performance.get('memory_used_mb', 0),
                    'gpu_memory_used_gb': performance.get('gpu_memory_used_gb', 0)
                })
            
            # Tri par mAP50 d√©croissant
            ranking.sort(key=lambda x: x['mAP50'], reverse=True)
            analysis['performance_ranking'] = ranking
            
            print(f"\nüèÜ CLASSEMENT PERFORMANCE:")
            for i, exp in enumerate(ranking, 1):
                print(f"{i}. {exp['experiment']}: mAP50={exp['mAP50']:.3f}, "
                      f"Dur√©e={exp['duration_minutes']:.1f}min")
            
            # Recommandations
            if ranking:
                best_experiment = ranking[0]
                analysis['recommendations'] = [
                    f"Meilleure configuration: {best_experiment['experiment']}",
                    f"mAP50 optimale: {best_experiment['mAP50']:.3f}",
                    f"Dur√©e d'entra√Ænement: {best_experiment['duration_minutes']:.1f} minutes"
                ]
                
                if len(ranking) > 1:
                    speed_ranking = sorted(ranking, key=lambda x: x['duration_minutes'])
                    fastest = speed_ranking[0]
                    if fastest['experiment'] != best_experiment['experiment']:
                        analysis['recommendations'].append(
                            f"Configuration la plus rapide: {fastest['experiment']} "
                            f"({fastest['duration_minutes']:.1f}min)"
                        )
            
            # Sauvegarde analyse
            analysis_file = f"{self.base_dir}/comprehensive_analysis.json"
            with open(analysis_file, 'w') as f:
                json.dump(analysis, f, indent=4, default=str)
            
            print(f"\nüíæ Analyse sauvegard√©e: {analysis_file}")
            
            return analysis
            
        except Exception as e:
            print(f"‚ùå Erreur analyse: {e}")
            return {'error': str(e)}
    
    def _calculate_average_metrics(self, experiment_results: Dict[str, Any]) -> Dict[str, float]:
        """Calcule les m√©triques moyennes pour un ensemble d'exp√©riences"""
        if not experiment_results:
            return {}
        
        metrics_sums = {
            'mAP50': 0,
            'mAP50_95': 0,
            'duration_minutes': 0,
            'memory_used_mb': 0,
            'gpu_memory_used_gb': 0
        }
        
        count = len(experiment_results)
        
        for exp_data in experiment_results.values():
            metrics = exp_data.get('metrics', {})
            performance = exp_data.get('performance', {})
            
            metrics_sums['mAP50'] += metrics.get('mAP50', 0)
            metrics_sums['mAP50_95'] += metrics.get('mAP50_95', 0)
            metrics_sums['duration_minutes'] += exp_data.get('duration_minutes', 0)
            metrics_sums['memory_used_mb'] += performance.get('memory_used_mb', 0)
            metrics_sums['gpu_memory_used_gb'] += performance.get('gpu_memory_used_gb', 0)
        
        return {k: v / count for k, v in metrics_sums.items()}
    
    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """G√©n√®re un rapport final complet"""
        print(f"\n{'='*60}")
        print("üìã G√âN√âRATION RAPPORT FINAL COMPLET")
        print(f"{'='*60}")
        
        try:
            session_end = datetime.now()
            session_start = datetime.fromisoformat(self.results['session_info']['start_time'])
            total_duration = (session_end - session_start).total_seconds()
            
            # R√©sum√© session
            experiments = self.results['experiments']
            successful_count = sum(1 for exp in experiments.values() if exp.get('success', False))
            
            summary = {
                'session_duration_minutes': total_duration / 60,
                'total_experiments': len(experiments),
                'successful_experiments': successful_count,
                'failed_experiments': len(experiments) - successful_count,
                'validation_success': self.results.get('validation_results', {}).get('ready_for_experiments', False),
                'dataset_used': self.results['session_info']['dataset_used'],
                'research_success': successful_count > 0
            }
            
            # Sauvegarde r√©sultats complets
            self.results['session_summary'] = summary
            results_file = f"{self.base_dir}/complete_session_results.json"
            with open(results_file, 'w') as f:
                json.dump(self.results, f, indent=4, default=str)
            
            # Rapport lisible
            report_file = f"{self.base_dir}/comprehensive_report.md"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("# üöÄ RAPPORT EXP√âRIENCES COMPARATIVES YOLO\n\n")
                print("## Sp√©cifications Setup\n")
                f.write(f"- **CPU:** AMD Ryzen 9 7945HX (12 cores)\n")
                f.write(f"- **RAM:** 39 GB disponible\n")
                f.write(f"- **Stockage:** 899 GB libre\n")
                f.write(f"- **OS:** Linux (WSL2)\n")
                f.write(f"- **Environnement:** flash-attention conda env\n\n")
                f.write(f"- **Session ID:** {self.session_id}\n")
                f.write(f"- **Dur√©e totale:** {summary['session_duration_minutes']:.1f} minutes\n")
                f.write(f"- **Date:** {session_end.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"- **Dataset:** {summary['dataset_used']}\n")
                f.write(f"- **Chercheur:** Kennedy Kitoko üá®üá©\n\n")
                
                f.write("## R√©sultats Exp√©riences\n")
                f.write(f"- **Total:** {summary['total_experiments']}\n")
                f.write(f"- **R√©ussies:** {summary['successful_experiments']}\n")
                f.write(f"- **√âchou√©es:** {summary['failed_experiments']}\n\n")
                
                # D√©tails par exp√©rience
                f.write("### D√©tails par Exp√©rience\n\n")
                for exp_name, exp_data in experiments.items():
                    status = "‚úÖ R√©ussie" if exp_data.get('success', False) else "‚ùå √âchou√©e"
                    f.write(f"#### {exp_name.upper()} - {status}\n")
                    
                    if exp_data.get('success', False):
                        metrics = exp_data.get('metrics', {})
                        f.write(f"- **Dur√©e:** {exp_data.get('duration_minutes', 0):.1f} minutes\n")
                        f.write(f"- **mAP50:** {metrics.get('mAP50', 0):.3f}\n")
                        f.write(f"- **mAP50-95:** {metrics.get('mAP50_95', 0):.3f}\n")
                        f.write(f"- **Pr√©cision:** {metrics.get('precision', 0):.3f}\n")
                        f.write(f"- **Rappel:** {metrics.get('recall', 0):.3f}\n")
                        
                        performance = exp_data.get('performance', {})
                        f.write(f"- **M√©moire utilis√©e:** {performance.get('memory_used_mb', 0):.1f} MB\n")
                        f.write(f"- **M√©moire GPU:** {performance.get('gpu_memory_used_gb', 0):.2f} GB\n")
                        
                        if exp_data.get('results_path'):
                            f.write(f"- **R√©sultats:** {exp_data['results_path']}\n")
                    else:
                        f.write(f"- **Erreur:** {exp_data.get('error', 'Inconnue')}\n")
                    
                    f.write("\n")
                
                # Analyse comparative
                analysis = self.results.get('comparative_analysis', {})
                if analysis:
                    f.write("## Analyse Comparative\n\n")
                    
                    if 'model_comparison' in analysis:
                        comp = analysis['model_comparison']
                        f.write("### YOLOv12 vs YOLOv13\n")
                        f.write(f"- **Gagnant:** {comp.get('winner', 'N/A').upper()}\n")
                        f.write(f"- **Diff√©rence mAP50:** {comp.get('mAP_difference', 0):.3f}\n")
                        f.write(f"- **Diff√©rence vitesse:** {comp.get('speed_difference_minutes', 0):.1f} min\n\n")
                    
                    if 'attention_comparison' in analysis:
                        comp = analysis['attention_comparison']
                        f.write("### SDPA vs Flash Attention\n")
                        f.write(f"- **Gagnant:** {comp.get('winner', 'N/A').upper()}\n")
                        f.write(f"- **Diff√©rence mAP50:** {comp.get('mAP_difference', 0):.3f}\n")
                        f.write(f"- **Diff√©rence vitesse:** {comp.get('speed_difference_minutes', 0):.1f} min\n\n")
                    
                    if 'performance_ranking' in analysis:
                        f.write("### Classement Performance\n")
                        for i, exp in enumerate(analysis['performance_ranking'], 1):
                            f.write(f"{i}. **{exp['experiment']}:** mAP50={exp['mAP50']:.3f}, "
                                  f"Dur√©e={exp['duration_minutes']:.1f}min\n")
                        f.write("\n")
                    
                    if 'recommendations' in analysis:
                        f.write("### Recommandations\n")
                        for rec in analysis['recommendations']:
                            f.write(f"- {rec}\n")
                        f.write("\n")
                
                f.write("## Innovations Techniques\n\n")
                f.write("### YOLOv13 - Innovations\n")
                f.write("- **HyperACE:** M√©canisme d'attention bas√© sur les hypergraphes\n")
                f.write("- **FullPAD:** Paradigme de distribution compl√®te des caract√©ristiques\n")
                f.write("- **DS-Blocks:** Blocs de convolution s√©parable en profondeur\n\n")
                
                f.write("### Flash Attention vs SDPA\n")
                f.write("- **SDPA:** Attention native PyTorch optimis√©e\n")
                f.write("- **Flash Attention:** Optimisation m√©moire avec r√©ordonnancement\n")
                f.write("- **Complexit√©:** Lin√©aire vs quadratique pour les longues s√©quences\n\n")
                
                f.write("---\n")
                f.write("**D√©velopp√© par Kennedy Kitoko üá®üá©**\n")
                f.write("*D√©mocratisation de l'IA pour l'Agriculture Mondiale*\n")
            
            print(f"üíæ Rapport complet: {report_file}")
            print(f"üíæ Donn√©es JSON: {results_file}")
            
            return summary
            
        except Exception as e:
            print(f"‚ùå Erreur rapport final: {e}")
            return {'error': str(e)}
    
    def run_complete_workflow(self, 
                            epochs: int = 100,  # Optimis√© setup Kennedy
                            batch_size: int = 16,  # Batch plus grand
                            skip_yolov13: bool = False) -> bool:
        """
        Workflow complet d'exp√©riences comparatives
        
        Args:
            epochs: Nombre d'√©poques par exp√©rience
            batch_size: Taille du batch
            skip_yolov13: Ignorer YOLOv13 si non disponible
        """
        print("üöÄ WORKFLOW COMPLET D'EXP√âRIENCES COMPARATIVES YOLO")
        print("üá®üá© Kennedy Kitoko - Agricultural AI Innovation")
        print("=" * 70)
        
        print(f"\nüìã Configuration:")
        print(f"   √âpoques: {epochs}")
        print(f"   Batch size: {batch_size}")
        print(f"   Skip YOLOv13: {skip_yolov13}")
        
        try:
            # Phase 1: Validation
            print(f"\n{'='*20}")
            print("PHASE 1: VALIDATION ENVIRONNEMENT")
            print(f"{'='*20}")
            
            if not self.comprehensive_validation():
                print("‚ùå Validation √©chou√©e - Arr√™t workflow")
                return False
            
            # V√©rification YOLOv13
            if not skip_yolov13 and not self.results['validation_results']['checks']['yolov13_weights_ok']:
                print("‚ö†Ô∏è YOLOv13 non disponible - Passage en mode YOLOv12 seulement")
                skip_yolov13 = True
            
            # Phase 2: Exp√©riences
            print(f"\n{'='*20}")
            print("PHASE 2: EXP√âRIENCES COMPARATIVES")
            print(f"{'='*20}")
            
            if skip_yolov13:
                # Mode YOLOv12 seulement
                print("üéØ Mode YOLOv12 uniquement")
                experiments_success = True
                
                # YOLOv12 + SDPA
                result_sdpa = self.run_yolo_experiment('yolov12', 'sdpa', epochs, batch_size)
                self.results['experiments']['yolov12_sdpa'] = result_sdpa
                
                # YOLOv12 + Flash
                result_flash = self.run_yolo_experiment('yolov12', 'flash', epochs, batch_size)
                self.results['experiments']['yolov12_flash'] = result_flash
                
                experiments_success = result_sdpa['success'] or result_flash['success']
            else:
                # Mode complet
                experiments_success = self.run_all_experiments(epochs, batch_size)
            
            # Phase 3: Analyse
            print(f"\n{'='*20}")
            print("PHASE 3: ANALYSE COMPARATIVE")
            print(f"{'='*20}")
            
            analysis = self.comprehensive_analysis()
            self.results['comparative_analysis'] = analysis
            
            # Phase 4: Rapport final
            print(f"\n{'='*20}")
            print("PHASE 4: RAPPORT FINAL")
            print(f"{'='*20}")
            
            summary = self.generate_comprehensive_report()
            
            # R√©sum√© final
            print(f"\n{'='*30}")
            print("üéâ WORKFLOW COMPARATIF TERMIN√â")
            print(f"{'='*30}")
            
            if summary.get('research_success', False):
                print("üèÜ SUCC√àS! Exp√©riences comparatives termin√©es")
                print("üìä Donn√©es scientifiques collect√©es et analys√©es")
                
                # Affichage r√©sum√© rapide
                successful = summary['successful_experiments']
                total = summary['total_experiments']
                print(f"‚úÖ Exp√©riences r√©ussies: {successful}/{total}")
                
                if 'comparative_analysis' in self.results and self.results['comparative_analysis']:
                    analysis = self.results['comparative_analysis']
                    
                    if 'performance_ranking' in analysis and analysis['performance_ranking']:
                        best = analysis['performance_ranking'][0]
                        print(f"ü•á Meilleure configuration: {best['experiment']}")
                        print(f"üìà mAP50 optimal: {best['mAP50']:.3f}")
                
            else:
                print("‚ö†Ô∏è Workflow partiel - Certaines exp√©riences ont √©chou√©")
                print("üíæ Donn√©es partielles sauvegard√©es")
            
            print(f"üìÅ Tous les r√©sultats dans: {self.base_dir}")
            
            return summary.get('research_success', False)
            
        except Exception as e:
            print(f"‚ùå Erreur workflow: {e}")
            print(f"üîç Traceback: {traceback.format_exc()}")
            return False


def main():
    """Point d'entr√©e principal"""
    print("üöÄ LANCEUR EXP√âRIENCES COMPARATIVES YOLO")
    print("üéØ YOLOv12 vs YOLOv13 - SDPA vs Flash Attention")
    print("üá®üá© Kennedy Kitoko - AI Democratization & Agricultural Innovation")
    print("=" * 70)
    
    print("\nüß† Contexte Technique:")
    print("üìã YOLOv12: Area Attention (A2) + R-ELAN + FlashAttention")
    print("üìã YOLOv13: HyperACE (Hypergraph) + FullPAD + DS-Blocks")
    print("üìã SDPA: Scaled Dot-Product Attention natif PyTorch")
    print("üìã Flash Attention: Optimisation m√©moire IO-aware")
    
    print("\nüî¨ Exp√©riences Planifi√©es:")
    print("1. YOLOv12 + SDPA")
    print("2. YOLOv12 + Flash Attention")
    print("3. YOLOv13 + SDPA")
    print("4. YOLOv13 + Flash Attention")
    
    # Configuration optimis√©e pour setup Kennedy
    # Setup d√©tect√©: AMD Ryzen 9 7945HX, 39GB RAM, 899GB libre
    default_epochs = 100  # Plus d'√©poques pour meilleure convergence
    default_batch = 16    # Batch plus grand avec 39GB RAM
    dataset_path = "/mnt/c/Users/kitok/Desktop/SmartFarm_OS/IA/YOLO12_FLASH_attn/Weeds-3"
    
    print(f"\n‚öôÔ∏è Configuration optimis√©e pour votre setup:")
    print(f"   üíª CPU: AMD Ryzen 9 7945HX (12 cores)")
    print(f"   üß† RAM: 39GB disponible")
    print(f"   üíæ Espace: 899GB libre")
    print(f"   üìä √âpoques: {default_epochs} (convergence optimale)")
    print(f"   üî¢ Batch size: {default_batch} (optimis√© RAM)")
    print(f"   üìÅ Dataset: Weeds-3 pr√©-configur√©")
    print(f"   ‚è±Ô∏è Dur√©e estim√©e: 4-8 heures (entra√Ænement complet)")
    print(f"   üíΩ Espace requis: ~15 GB (tous mod√®les)")
    
    # Options interactives
    try:
        print(f"\nüîß Configuration (Entr√©e = d√©faut):")
        
        # √âpoques
        epochs_input = input(f"√âpoques [{default_epochs}]: ").strip()
        epochs = int(epochs_input) if epochs_input else default_epochs
        
        # Batch size
        batch_input = input(f"Batch size [{default_batch}]: ").strip()
        batch_size = int(batch_input) if batch_input else default_batch
        
        # Dataset personnalis√©
        dataset_input = input("Chemin dataset [auto]: ").strip()
        dataset_path = dataset_input if dataset_input else None
        
        # Mode rapide optimis√© pour tests
        quick_mode = input("Mode rapide (50 √©poques au lieu de 100) ? [n]: ").strip().lower()
        if quick_mode in ['y', 'yes', 'oui']:
            epochs = 50
            print(f"‚ö° Mode rapide activ√© - √âpoques: {epochs}")
        
        # Mode ultra-rapide pour d√©veloppement
        dev_mode = input("Mode d√©veloppeur (20 √©poques, tests rapides) ? [n]: ").strip().lower()
        if dev_mode in ['y', 'yes', 'oui']:
            epochs = 20
            batch_size = min(batch_size, 8)  # Batch plus petit pour tests
            print(f"üîß Mode d√©veloppeur activ√© - √âpoques: {epochs}, Batch: {batch_size}")
        
        # GPU detection et optimisation batch
        try:
            import torch
            if torch.cuda.is_available():
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
                print(f"\nüéÆ GPU d√©tect√©: {gpu_name} ({gpu_memory:.1f} GB)")
                
                # Ajustement batch selon GPU
                if gpu_memory >= 24:  # RTX 4090, A100, etc.
                    suggested_batch = min(batch_size * 2, 32)
                    increase_batch = input(f"GPU puissant d√©tect√©. Augmenter batch √† {suggested_batch}? [n]: ").strip().lower()
                    if increase_batch in ['y', 'yes', 'oui']:
                        batch_size = suggested_batch
                        print(f"üöÄ Batch augment√© √† {batch_size}")
                elif gpu_memory < 8:  # GPU plus modeste
                    suggested_batch = max(batch_size // 2, 4)
                    print(f"‚ö†Ô∏è GPU modeste d√©tect√©. R√©duction batch recommand√©e: {suggested_batch}")
                    reduce_batch = input(f"R√©duire batch √† {suggested_batch}? [y]: ").strip().lower()
                    if reduce_batch not in ['n', 'no', 'non']:
                        batch_size = suggested_batch
                        print(f"üìâ Batch r√©duit √† {batch_size}")
            else:
                print("‚ö†Ô∏è Pas de GPU d√©tect√© - Mode CPU (tr√®s lent)")
                epochs = min(epochs, 10)
                batch_size = min(batch_size, 4)
                print(f"üêå Mode CPU: √âpoques={epochs}, Batch={batch_size}")
                
        except ImportError:
            pass
        
        # Confirmation finale
        print(f"\nüìã Configuration finale:")
        print(f"   √âpoques: {epochs}")
        print(f"   Batch size: {batch_size}")
        print(f"   Dataset: {dataset_path or 'Auto-d√©tection'}")
        
        confirm = input("\nüöÄ Lancer les exp√©riences comparatives? [Y/n]: ").strip().lower()
        if confirm in ['n', 'no', 'non']:
            print("‚ùå Exp√©riences annul√©es")
            return False
            
    except KeyboardInterrupt:
        print("\n‚ùå Exp√©riences annul√©es par l'utilisateur")
        return False
    except ValueError as e:
        print(f"‚ùå Erreur configuration: {e}")
        return False
    
    # Lancement exp√©riences
    launcher = ComprehensiveYOLOExperimentLauncher(dataset_path)
    
    try:
        success = launcher.run_complete_workflow(
            epochs=epochs,
            batch_size=batch_size,
            skip_yolov13=False  # Tentera YOLOv13, passera en mode YOLOv12 si non disponible
        )
        
        if success:
            print("\nüèÜ EXP√âRIENCES COMPARATIVES R√âUSSIES!")
            print("üìä Analyse compl√®te YOLOv12 vs YOLOv13")
            print("üî¨ Comparaison SDPA vs Flash Attention")
            print("üìà M√©triques de performance collect√©es")
        else:
            print("\nüìã EXP√âRIENCES PARTIELLES")
            print("üíæ Certaines donn√©es collect√©es")
            print("üîç V√©rifier les logs pour plus de d√©tails")
        
        return success
        
    except Exception as e:
        print(f"\n‚ùå Erreur exp√©riences: {e}")
        print(f"üîç Traceback: {traceback.format_exc()}")
        return False


if __name__ == "__main__":
    success = main()
    
    print(f"\n{'='*70}")
    print("üá®üá© Kennedy Kitoko - Agricultural AI Innovation")
    print("üåç Democratizing AI for Global Agriculture")
    print("üß† HyperACE: Hypergraph-Enhanced Adaptive Visual Perception")
    print("‚ö° Flash Attention: Memory-Efficient IO-Aware Computation")
    print("üìö SDPA: Scaled Dot-Product Attention Excellence")
    print(f"{'='*70}")
    
    sys.exit(0 if success else 1)