#!/usr/bin/env python3
"""
üîÑ SCRIPT DE REPRODUCTION DES EXP√âRIENCES
YOLOv12 vs YOLOv13 - SDPA vs Flash Attention Study
D√©velopp√© par Kennedy Kitoko üá®üá©
"""

import os
import sys
import json
import argparse
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict, Any

class ExperimentReproducer:
    """Reproducteur d'exp√©riences YOLO avec validation compl√®te"""
    
    def __init__(self):
        self.base_dir = Path.cwd()
        self.configs = self._load_experiment_configs()
        
    def _load_experiment_configs(self) -> Dict[str, Any]:
        """Charge les configurations d'exp√©riences valid√©es"""
        return {
            'yolov12_sdpa': {
                'model': 'yolo12n.pt',
                'attention': 'sdpa',
                'expected_map50': 76.72,
                'expected_duration_min': 55.3,
                'epochs': 20,
                'batch': 8,
                'description': 'YOLOv12 with native PyTorch SDPA'
            },
            'yolov12_flash': {
                'model': 'yolo12n.pt', 
                'attention': 'flash',
                'expected_map50': 76.53,
                'expected_duration_min': 67.3,
                'epochs': 20,
                'batch': 8,
                'description': 'YOLOv12 with Flash Attention 2.7.3'
            },
            'yolov13_sdpa': {
                'model': 'yolov13n.pt',
                'attention': 'sdpa',
                'expected_map50': 82.9,
                'expected_duration_min': 58.6,
                'epochs': 20,
                'batch': 8,
                'description': 'YOLOv13 with HyperACE + SDPA'
            },
            'yolov13_flash': {
                'model': 'yolov13n.pt',
                'attention': 'flash', 
                'expected_map50': 82.3,
                'expected_duration_min': 65.7,
                'epochs': 20,
                'batch': 8,
                'description': 'YOLOv13 with HyperACE + Flash Attention'
            }
        }
    
    def validate_environment(self) -> bool:
        """Validation compl√®te de l'environnement de reproduction"""
        print("üîç VALIDATION ENVIRONNEMENT DE REPRODUCTION")
        print("=" * 50)
        
        checks = {
            'python': False,
            'torch': False,
            'cuda': False,
            'ultralytics': False,
            'flash_attn': False,
            'dataset': False,
            'weights': False
        }
        
        # Python version
        if sys.version_info >= (3, 8):
            checks['python'] = True
            print(f"‚úÖ Python {sys.version_info.major}.{sys.version_info.minor}")
        else:
            print(f"‚ùå Python {sys.version_info.major}.{sys.version_info.minor} (requis: ‚â•3.8)")
        
        # PyTorch + CUDA
        try:
            import torch
            checks['torch'] = True
            print(f"‚úÖ PyTorch {torch.__version__}")
            
            if torch.cuda.is_available():
                checks['cuda'] = True
                print(f"‚úÖ CUDA {torch.version.cuda} - {torch.cuda.get_device_name(0)}")
            else:
                print("‚ùå CUDA non disponible")
        except ImportError:
            print("‚ùå PyTorch non install√©")
        
        # Ultralytics
        try:
            from ultralytics import YOLO
            checks['ultralytics'] = True
            print("‚úÖ Ultralytics YOLO")
        except ImportError:
            print("‚ùå Ultralytics non install√©")
        
        # Flash Attention
        try:
            import flash_attn
            checks['flash_attn'] = True
            print(f"‚úÖ Flash Attention {getattr(flash_attn, '__version__', 'unknown')}")
        except ImportError:
            print("‚ö†Ô∏è Flash Attention non disponible (optionnel)")
        
        # Dataset Weeds-3
        dataset_paths = [
            'Weeds-3',
            '/mnt/c/Users/kitok/Desktop/SmartFarm_OS/IA/YOLO12_FLASH_attn/Weeds-3',
            '../Weeds-3'
        ]
        
        for path in dataset_paths:
            if os.path.exists(os.path.join(path, 'train', 'images')):
                checks['dataset'] = True
                print(f"‚úÖ Dataset: {os.path.abspath(path)}")
                self.dataset_path = os.path.abspath(path)
                break
        
        if not checks['dataset']:
            print("‚ùå Dataset Weeds-3 non trouv√©")
        
        # Poids mod√®les
        weights_available = []
        for config_name, config in self.configs.items():
            model_file = config['model']
            if os.path.exists(model_file):
                weights_available.append(model_file)
        
        if len(weights_available) >= 2:
            checks['weights'] = True
            print(f"‚úÖ Poids mod√®les: {', '.join(weights_available)}")
        else:
            print(f"‚ö†Ô∏è Poids partiels: {', '.join(weights_available)}")
        
        # R√©sum√© validation
        critical_checks = ['python', 'torch', 'cuda', 'ultralytics', 'dataset']
        critical_passed = sum(checks[check] for check in critical_checks)
        
        ready = critical_passed >= 5
        
        print(f"\nüìä Validation: {sum(checks.values())}/{len(checks)} checks")
        print(f"üéØ Critique: {critical_passed}/{len(critical_checks)} essentiels")
        print(f"üèÅ Pr√™t pour reproduction: {'Oui' if ready else 'Non'}")
        
        return ready
    
    def reproduce_single_experiment(self, config_name: str, 
                                  epochs: Optional[int] = None,
                                  batch: Optional[int] = None,
                                  quick_mode: bool = False) -> Dict[str, Any]:
        """Reproduit une exp√©rience sp√©cifique"""
        
        if config_name not in self.configs:
            raise ValueError(f"Configuration inconnue: {config_name}")
        
        config = self.configs[config_name].copy()
        
        # Override param√®tres si sp√©cifi√©s
        if epochs:
            config['epochs'] = epochs
        if batch:
            config['batch'] = batch
        if quick_mode:
            config['epochs'] = min(config['epochs'], 5)
        
        print(f"\nüî¨ REPRODUCTION: {config_name.upper()}")
        print(f"üìã {config['description']}")
        print("=" * 50)
        
        # Import du script principal
        try:
            from comprehensive_yolo_experiments import ComprehensiveYOLOExperimentLauncher
        except ImportError:
            print("‚ùå Script principal non trouv√©")
            return {'success': False, 'error': 'Script principal manquant'}
        
        # Configuration launcher
        launcher = ComprehensiveYOLOExperimentLauncher(self.dataset_path)
        
        # Extraction mod√®le et attention
        model_version = 'yolov12' if 'yolov12' in config_name else 'yolov13'
        attention_type = config['attention']
        
        print(f"üéØ Mod√®le: {model_version}")
        print(f"‚ö° Attention: {attention_type}")
        print(f"üìä √âpoques: {config['epochs']}")
        print(f"üî¢ Batch: {config['batch']}")
        
        # Lancement exp√©rience
        try:
            start_time = datetime.now()
            
            result = launcher.run_yolo_experiment(
                model_version=model_version,
                attention_type=attention_type,
                epochs=config['epochs'],
                batch_size=config['batch']
            )
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds() / 60
            
            # Validation r√©sultats
            if result['success']:
                actual_map50 = result['metrics']['mAP50'] * 100
                expected_map50 = config['expected_map50']
                map50_diff = abs(actual_map50 - expected_map50)
                
                print(f"\nüìà R√âSULTATS REPRODUCTION:")
                print(f"   mAP50: {actual_map50:.2f}% (attendu: {expected_map50:.2f}%)")
                print(f"   Diff√©rence: {map50_diff:.2f}%")
                print(f"   Dur√©e: {duration:.1f} min (attendu: {config['expected_duration_min']:.1f} min)")
                
                # Tol√©rance validation
                tolerance = 3.0 if quick_mode else 1.5  # % de tol√©rance
                validated = map50_diff <= tolerance
                
                result['reproduction_validation'] = {
                    'validated': validated,
                    'actual_map50': actual_map50,
                    'expected_map50': expected_map50,
                    'map50_difference': map50_diff,
                    'tolerance': tolerance,
                    'duration_actual': duration,
                    'duration_expected': config['expected_duration_min']
                }
                
                if validated:
                    print("‚úÖ Reproduction valid√©e (dans tol√©rance)")
                else:
                    print(f"‚ö†Ô∏è Reproduction hors tol√©rance (>{tolerance}%)")
            
            return result
            
        except Exception as e:
            print(f"‚ùå Erreur reproduction: {e}")
            return {
                'success': False,
                'error': str(e),
                'config': config_name
            }
    
    def reproduce_all_experiments(self, epochs: Optional[int] = None,
                                batch: Optional[int] = None,
                                quick_mode: bool = False) -> Dict[str, Any]:
        """Reproduit toutes les exp√©riences"""
        print("üöÄ REPRODUCTION COMPL√àTE - TOUTES EXP√âRIENCES")
        print("üá®üá© Kennedy Kitoko - Agricultural AI Innovation")
        print("=" * 60)
        
        results = {}
        successful_reproductions = 0
        validated_reproductions = 0
        
        for config_name in self.configs.keys():
            try:
                print(f"\n{'='*20}")
                print(f"EXP√âRIENCE {len(results)+1}/4: {config_name.upper()}")
                print(f"{'='*20}")
                
                result = self.reproduce_single_experiment(
                    config_name, epochs, batch, quick_mode
                )
                
                results[config_name] = result
                
                if result['success']:
                    successful_reproductions += 1
                    if result.get('reproduction_validation', {}).get('validated', False):
                        validated_reproductions += 1
                
                # Pause entre exp√©riences
                if len(results) < len(self.configs):
                    print("‚è∏Ô∏è Pause nettoyage m√©moire...")
                    try:
                        import torch
                        import gc
                        if torch.cuda.is_available():
                            torch.cuda.empty_cache()
                        gc.collect()
                        import time
                        time.sleep(5)
                    except:
                        pass
                        
            except Exception as e:
                print(f"‚ùå Erreur exp√©rience {config_name}: {e}")
                results[config_name] = {
                    'success': False,
                    'error': str(e)
                }
        
        # R√©sum√© final
        print(f"\n{'='*30}")
        print("üéâ REPRODUCTION TERMIN√âE")
        print(f"{'='*30}")
        
        print(f"üìä Exp√©riences r√©ussies: {successful_reproductions}/{len(self.configs)}")
        print(f"‚úÖ Reproductions valid√©es: {validated_reproductions}/{successful_reproductions}")
        
        # Sauvegarde r√©sultats
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        results_file = f"reproduction_results_{timestamp}.json"
        
        reproduction_summary = {
            'timestamp': datetime.now().isoformat(),
            'total_experiments': len(self.configs),
            'successful_reproductions': successful_reproductions,
            'validated_reproductions': validated_reproductions,
            'parameters': {
                'epochs': epochs,
                'batch': batch,
                'quick_mode': quick_mode
            },
            'results': results
        }
        
        with open(results_file, 'w') as f:
            json.dump(reproduction_summary, f, indent=4, default=str)
        
        print(f"üíæ R√©sultats sauvegard√©s: {results_file}")
        
        return reproduction_summary
    
    def compare_with_original(self, reproduction_results: Dict[str, Any]):
        """Compare les r√©sultats reproduits avec les originaux"""
        print("\nüìä COMPARAISON AVEC R√âSULTATS ORIGINAUX")
        print("=" * 50)
        
        # R√©sultats originaux de r√©f√©rence
        original_results = {
            'yolov12_sdpa': {'mAP50': 76.72, 'duration': 55.3},
            'yolov12_flash': {'mAP50': 76.53, 'duration': 67.3},
            'yolov13_sdpa': {'mAP50': 82.9, 'duration': 58.6},
            'yolov13_flash': {'mAP50': 82.3, 'duration': 65.7}
        }
        
        comparison = {}
        
        for exp_name in original_results.keys():
            if exp_name in reproduction_results['results']:
                repro_result = reproduction_results['results'][exp_name]
                original = original_results[exp_name]
                
                if repro_result['success']:
                    actual_map50 = repro_result['metrics']['mAP50'] * 100
                    duration = repro_result['duration_minutes']
                    
                    map50_diff = actual_map50 - original['mAP50']
                    duration_diff = duration - original['duration']
                    
                    comparison[exp_name] = {
                        'original_map50': original['mAP50'],
                        'reproduced_map50': actual_map50,
                        'map50_difference': map50_diff,
                        'original_duration': original['duration'],
                        'reproduced_duration': duration,
                        'duration_difference': duration_diff
                    }
                    
                    print(f"\n{exp_name.upper()}:")
                    print(f"  mAP50: {original['mAP50']:.2f}% ‚Üí {actual_map50:.2f}% ({map50_diff:+.2f}%)")
                    print(f"  Dur√©e: {original['duration']:.1f}min ‚Üí {duration:.1f}min ({duration_diff:+.1f}min)")
        
        return comparison


def main():
    """Point d'entr√©e principal"""
    parser = argparse.ArgumentParser(description='üîÑ Reproduction Exp√©riences YOLO')
    
    parser.add_argument('--config', type=str, choices=['yolov12_sdpa', 'yolov12_flash', 'yolov13_sdpa', 'yolov13_flash'],
                      help='Configuration sp√©cifique √† reproduire')
    parser.add_argument('--all', action='store_true', help='Reproduire toutes les exp√©riences')
    parser.add_argument('--epochs', type=int, help='Nombre d\'√©poques (override)')
    parser.add_argument('--batch', type=int, help='Taille du batch (override)')
    parser.add_argument('--quick', action='store_true', help='Mode rapide (5 √©poques max)')
    parser.add_argument('--validate-env', action='store_true', help='Validation environnement seulement')
    
    args = parser.parse_args()
    
    print("üîÑ REPRODUCTEUR EXP√âRIENCES YOLO")
    print("üéØ YOLOv12 vs YOLOv13 - SDPA vs Flash Attention")
    print("üá®üá© Kennedy Kitoko - Agricultural AI Innovation")
    print("=" * 60)
    
    # Initialisation
    reproducer = ExperimentReproducer()
    
    # Validation environnement
    if not reproducer.validate_environment():
        print("‚ùå Environnement non pr√™t pour reproduction")
        return False
    
    if args.validate_env:
        print("‚úÖ Validation environnement termin√©e")
        return True
    
    try:
        if args.config:
            # Reproduction exp√©rience sp√©cifique
            result = reproducer.reproduce_single_experiment(
                args.config, args.epochs, args.batch, args.quick
            )
            
            if result['success']:
                print(f"‚úÖ Reproduction {args.config} r√©ussie")
                return True
            else:
                print(f"‚ùå Reproduction {args.config} √©chou√©e")
                return False
                
        elif args.all:
            # Reproduction toutes exp√©riences
            results = reproducer.reproduce_all_experiments(
                args.epochs, args.batch, args.quick
            )
            
            # Comparaison avec originaux
            reproducer.compare_with_original(results)
            
            success_rate = results['validated_reproductions'] / results['total_experiments']
            print(f"\nüéØ Taux de r√©ussite reproduction: {success_rate:.1%}")
            
            return success_rate >= 0.75  # 75% minimum
            
        else:
            parser.print_help()
            return False
            
    except Exception as e:
        print(f"‚ùå Erreur reproduction: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    
    print(f"\n{'='*60}")
    print("üá®üá© Kennedy Kitoko - Agricultural AI Innovation")
    print("üåç Democratizing AI for Global Agriculture")
    print("üîÑ Experiment Reproduction Framework")
    print("üî¨ Ensuring Scientific Reproducibility")
    print(f"{'='*60}")
    
    sys.exit(0 if success else 1)